# BondforOC Pipeline

Pipeline completa per l'estrazione, validazione e arricchimento di metadati bibliografici utilizzando Crossref e OpenCitations.

## ðŸ“‹ Indice

- [Panoramica](#panoramica)
- [Requisiti](#requisiti)
- [Struttura della Pipeline](#struttura-della-pipeline)
- [Installazione](#installazione)
- [Guida all'Uso](#guida-alluso)
- [File di Output](#file-di-output)
- [Statistiche Attese](#statistiche-attese)
- [Note Tecniche](#note-tecniche)

---

## ðŸŽ¯ Panoramica

Questa pipeline processa dataset bibliografici attraverso tre fasi principali:

1. **Preparazione Gold Standard** - Verifica e divisione del dataset in training/validation
2. **Validazione Crossref** - Matching dei paper con Crossref e estrazione DOI
3. **Arricchimento OpenCitations** - Recupero metadati e citazioni da OpenCitations

### Flusso Completo

```
Gold Standard CSV
      â†“
[process_gold_standard_1.py]
      â†“
Training/Validation Sets
      â†“
[crossref_query_2.py] â†’ Analisi e ottimizzazione cutoff
      â†“
[crossref_query_for_Bond_3.py] â†’ Validazione massiva
      â†“
validated_keys_dois.csv
      â†“
[opencitations_query_4.py] â†’ Metadati + Citazioni
      â†“
converted_metadata.json
      â†“
[sna_raw_creation.py] â†’ Formato autore-centrico
      â†“
converted_metadata_raw.json
```

---

## ðŸ’» Requisiti

### Software
- Python 3.8+
- Connessione internet stabile

### Librerie Python
```bash
pip install requests
pip install chardet
pip install matplotlib
pip install python-Levenshtein
pip install tqdm
```

### Token API
- **OpenCitations Access Token** (gratuito): [Richiedi qui](https://opencitations.net/accesstoken)

---

## ðŸ”§ Struttura della Pipeline

### 1. `process_gold_standard_1.py`

**Scopo**: Prepara il gold standard verificando i DOI su Crossref e dividendo in training/validation.

**Input**:
- `gold_standard.csv` - CSV con colonne: `Key`, `title`, `DOI`, `Cinese_title`

**Output**:
- `results/training_set.csv` - 300 esempi per training
- `results/validation_set.csv` - Rimanenti esempi per validazione
- `results/failed_requests.csv` - DOI con errori API

**Parametri Configurabili**:
```python
MAX_RETRIES = 3          # Tentativi per ogni richiesta
RETRY_DELAY = 5          # Secondi tra i retry
training_size = 300      # Dimensione training set
```

**Esecuzione**:
```bash
python process_gold_standard_1.py
```

---

### 2. `crossref_query_2.py`

**Scopo**: Analizza il training set per trovare il cutoff ottimale di Crossref score.

**Input**:
- `data/Bondvalidation.json` - Metadati paper in formato JSON
- `results/training_set.csv` - Training set preparato
- `results/validation_set.csv` - Validation set

**Output**:
- `results/crossref_score_analysis.png` - Grafico scatter plot
- `results/crossref_cutoff_analysis.csv` - Metriche per ogni cutoff
- `results/validation_results.csv` - Risultati validation set
- `results/crossref_training_cache.json` - Cache query Crossref
- `results/wrong_matches_analysis.csv` - Analisi errori

**Caratteristiche**:
- âœ… Sistema di caching intelligente
- âœ… Validazione con Levenshtein distance (similaritÃ  titoli)
- âœ… Verifica esatta dell'anno
- âœ… Calcolo automatico del cutoff ottimale

**Esecuzione**:
```bash
# Con cutoff automatico
python crossref_query_2.py

# Con cutoff manuale
# Modifica nel file: main(manual_cutoff=35.0)
```

**Metriche Calcolate**:
- Accuracy
- Precision
- Recall
- F1 Score

---

### 3. `crossref_query_for_Bond_3.py`

**Scopo**: Validazione massiva del dataset completo con multiprocessing.

**Input**:
- `data/Bondvalidation.json` - Dataset completo
- Cutoff ottimale da fase 2

**Output**:
- `results/Bond_crossref_validated/validated_keys_dois.csv` - Paper validati con DOI
- `results/Bond_crossref_validated/rejected_items.csv` - Paper rifiutati
- `results/Bond_crossref_validated/error_items.csv` - Paper con errori
- `results/crossref_cache.json` - Cache globale

**Parametri Configurabili**:
```python
manual_cutoff = 35.0      # Cutoff Crossref score
num_processes = 4         # Processi paralleli
use_cache = True          # Usa cache
```

**Caratteristiche**:
- ðŸš€ Multiprocessing per velocizzare l'elaborazione
- ðŸ”„ Progress bar con `tqdm`
- ðŸ’¾ Cache condivisa tra processi
- âœ… Validazione metadati (titolo + anno)

**Esecuzione**:
```bash
python crossref_query_for_Bond_3.py
```

**Stima Tempi**: ~30 secondi per 100 paper (con 4 processi)

---

### 4. `opencitations_query_4.py` â­ **NUOVO**

**Scopo**: Recupera metadati bibliografici e citazioni da OpenCitations (API v2).

**Input**:
- `validated_keys_dois.csv` - Paper validati con DOI

**Output**:

**ModalitÃ  1 - Standard** (`OC_results/`):
- `converted_metadata.json` - Metadati formato target
- `opencitations_metadata.json` - Metadati formato originale
- `final_batch_notfound.json` - DOI non trovati
- `processing_summary.json` - Statistiche
- `opencitations_cache.json` - Cache
- `opencitations_app.log` - Log dettagliato

**ModalitÃ  2 - Con Citazioni** (`OC_results_with_citations/`):
- Stesso output della ModalitÃ  1 +
- `outgoing_citations`: Lista DOI citati da questo paper
- `incoming_citations`: Lista DOI che citano questo paper
- `*_count`: Conteggi citazioni

**Formato Output Convertito**:
```json
{
  "paper_key": {
    "id": "paper_key",
    "title": "Paper Title",
    "abstract": "",
    "keywords": ["keyword1", "keyword2"],
    "authors": [
      {"name": "Author Name", "org": ""}
    ],
    "venue": "Journal Name",
    "year": 2020,
    "outgoing_citations": ["10.1234/doi1"],
    "incoming_citations": ["10.5678/doi2"],
    "outgoing_citations_count": 1,
    "incoming_citations_count": 1
  }
}
```

**Caratteristiche**:
- ðŸ†• API OpenCitations v2 (META + INDEX)
- ðŸ”€ Due modalitÃ  di esecuzione
- ðŸ§ª Fase test con primi 100 DOI
- ðŸ”„ Sistema retry intelligente
- ðŸ’¾ Caching avanzato
- âš¡ Gestione rate limiting
- ðŸ“Š Statistiche dettagliate

**Esecuzione**:
```bash
python opencitations_query_4.py

# Selezione modalitÃ  interattiva:
# 1. Solo metadati
# 2. Metadati + citazioni (3x piÃ¹ lento)
```

**Fasi di Esecuzione**:
1. **Selezione modalitÃ ** - Scegli se includere citazioni
2. **Test batch** - Elabora primi 100 DOI
3. **Verifica risultati** - Controlla file output
4. **Elaborazione completa** - Processa tutti i DOI (opzionale)
5. **Retry** - Riprova DOI falliti nelle esecuzioni successive

**Stima Tempi**:
- ModalitÃ  Standard: ~1 minuto per 100 DOI
- ModalitÃ  Citazioni: ~3 minuti per 100 DOI

**API Endpoint Utilizzati**:
```
META API:   https://api.opencitations.net/meta/v1/metadata/doi:{DOI}
INDEX API:  https://api.opencitations.net/index/v2/citations/doi:{DOI}
            https://api.opencitations.net/index/v2/references/doi:{DOI}
```

---

### 5. `sna_raw_creation.py`

**Scopo**: Converte metadati da formato paper-centrico a formato autore-centrico.

**Input**:
- `results/OC_results/converted_metadata.json`

**Output**:
- `results/converted_metadata_raw.json` - Formato autore â†’ paper

**Formato Output**:
```json
{
  "mario_rossi": ["paper1", "paper2"],
  "john_doe": ["paper3"]
}
```

**Normalizzazione Nomi**:
- Lowercase
- Rimozione abbreviazioni (J. â†’ j)
- Rimozione caratteri speciali
- Formato: `primo_nome_cognome`
- Limite: 100 caratteri

**Esecuzione**:
```bash
python sna_raw_creation.py
```

---

## ðŸ“¦ Installazione

### 1. Clona la Repository
```bash
git clone https://github.com/tuouser/BondforOC.git
cd BondforOC
```

### 2. Crea Ambiente Virtuale
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

### 3. Installa Dipendenze
```bash
pip install -r requirements.txt
```

### 4. Configura Token OpenCitations
Apri `opencitations_query_4.py` e inserisci il tuo token:
```python
OPENCITATIONS_ACCESS_TOKEN = "IL-TUO-TOKEN-QUI"
```

### 5. Prepara i Dati
Posiziona i tuoi file in:
```
data/
  â”œâ”€â”€ gold_standard.csv
  â””â”€â”€ Bondvalidation.json
```

---

## ðŸš€ Guida all'Uso

### Workflow Completo

#### Step 1: Prepara Gold Standard
```bash
python process_gold_standard_1.py
```
âœ… Verifica: Controlla `results/training_set.csv` e `results/validation_set.csv`

#### Step 2: Trova Cutoff Ottimale
```bash
python crossref_query_2.py
```
âœ… Verifica: Guarda `results/crossref_score_analysis.png` per il cutoff suggerito

#### Step 3: Valida Dataset Completo
```bash
# Aggiorna il cutoff in crossref_query_for_Bond_3.py
# Poi esegui:
python crossref_query_for_Bond_3.py
```
âœ… Verifica: Controlla `results/Bond_crossref_validated/validated_keys_dois.csv`

#### Step 4: Recupera Metadati OpenCitations
```bash
python opencitations_query_4.py

# Seleziona modalitÃ :
# 1 = Solo metadati (veloce)
# 2 = Metadati + citazioni (completo ma lento)
```
âœ… Verifica: Controlla `results/OC_results/converted_metadata.json`

#### Step 5: Crea Formato Autore-Centrico
```bash
python sna_raw_creation.py
```
âœ… Verifica: Controlla `results/converted_metadata_raw.json`

---

## ðŸ“ File di Output

### Struttura Directory Results
```
results/
â”œâ”€â”€ training_set.csv
â”œâ”€â”€ validation_set.csv
â”œâ”€â”€ failed_requests.csv
â”œâ”€â”€ crossref_score_analysis.png
â”œâ”€â”€ crossref_cutoff_analysis.csv
â”œâ”€â”€ validation_results.csv
â”œâ”€â”€ validation_metrics.json
â”œâ”€â”€ wrong_matches_analysis.csv
â”œâ”€â”€ crossref_cache.json
â”œâ”€â”€ Bond_crossref_validated/
â”‚   â”œâ”€â”€ validated_keys_dois.csv
â”‚   â”œâ”€â”€ rejected_items.csv
â”‚   â””â”€â”€ error_items.csv
â”œâ”€â”€ OC_results/
â”‚   â”œâ”€â”€ converted_metadata.json
â”‚   â”œâ”€â”€ opencitations_metadata.json
â”‚   â”œâ”€â”€ final_batch_notfound.json
â”‚   â”œâ”€â”€ processing_summary.json
â”‚   â”œâ”€â”€ opencitations_cache.json
â”‚   â””â”€â”€ opencitations_app.log
â”œâ”€â”€ OC_results_with_citations/
â”‚   â””â”€â”€ (stessi file di OC_results con citazioni)
â””â”€â”€ converted_metadata_raw.json
```

---

## ðŸ“Š Statistiche Attese

### Crossref Validation
- **Precision**: 95-98%
- **Recall**: 85-90%
- **Coverage**: ~90% dei DOI validabili

### OpenCitations
- **Coverage**: ~40-60% dei DOI (varia per disciplina)
- **Citazioni**: Media 10-50 citazioni per paper
- **Successo Rate**: ~70-80% dei DOI cercati

---

## ðŸ“ Note Tecniche

### Normalizzazione DOI
I DOI vengono normalizzati rimuovendo:
- Prefissi: `https://doi.org/`, `http://doi.org/`, `doi.org/`, `DOI:`, `doi:`
- Convertiti in lowercase
- Spazi rimossi

### Validazione Metadati
La validazione richiede:
- **Titolo**: SimilaritÃ  Levenshtein > 50%
- **Anno**: Match esatto
- **Autori**: Check disabilitato di default (opzionale)

### Cache Behavior
- Cache salvata ogni 100 richieste
- Backup automatico se corrotta
- Condivisa tra processi (multiprocessing)

### Problemi Comuni e Soluzioni

#### JSONDecodeError in OpenCitations
L'API restituisce HTML invece di JSON quando il DOI non esiste nel database. Il sistema marca automaticamente questi DOI come "non trovati".

#### Rate Limiting (HTTP 429)
Il sistema attende automaticamente quando viene raggiunto il rate limit. Se il problema persiste, aumentare `RATE_LIMIT_DELAY` in `opencitations_query_4.py`.

#### Token OpenCitations non valido
Richiedere un nuovo token gratuito su https://opencitations.net/accesstoken

#### Cache corrotta
Cancellare i file `*cache.json` e rieseguire gli script per rigenerare la cache.

---

**Versione**: 2.0  
**Ultimo Aggiornamento**: Ottobre 2025 Normalizzazione DOI
I DOI vengono normalizzati rimuovendo:
- Prefissi: `https://doi.org/`, `http://doi.org/`, `doi.org/`, `DOI:`, `doi:`
- Convertiti in lowercase
- Spazi rimossi

### Validazione Metadati
La validazione richiede:
- **Titolo**: SimilaritÃ  Levenshtein > 50%
- **Anno**: Match esatto
- **Autori**: Check disabilitato di default (opzionale)

### Cache Behavior
- Cache salvata ogni 100 richieste
- Backup automatico se corrotta
- Condivisa tra processi (multiprocessing)

---

**Versione**: 2.0  
**Ultimo Aggiornamento**: Ottobre 2025